{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SENTIMENT ANALYSIS - UNSUPERVISED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.wsd import lesk\n",
    "from textserver import TextServer\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('login.env')\n",
    "ts_password = os.getenv(\"PASSWORD_CAI\")\n",
    "ts_user = os.getenv(\"USER_CAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets    \n",
    "with open('./data/X_test.json', 'r') as file:\n",
    "    X_test = json.load(file)\n",
    "    \n",
    "with open('./data/y_test.json', 'r') as file:\n",
    "    y_test = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TextServer(ts_user, ts_password, 'senses') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "example_sent = \"i guess that if a very wild bachelor party had gone really bad , there would be broken furniture , traces of smack and cocaine on the floor , and a dead prostitute in the bathroom . i guess that if a movie had also gone really bad , there might be the same elements present . coincidence ? poor kyle ( a meek looking jon favreau ) . . . he is about to marry his radiant fiancee , laura ( cameron diaz ) . but before he exchanges his vows , he embarks to las vegas with his friends for one last blowout . but this bachelor party has gone about as bad as it could possibly get . the prostitute has met a horrible , though accidental death , and drugs are everywhere . the five friends agree that there is enough bad evidence here that will send them to jail for a very long time . a surprisingly calm robert boyd ( christian slater ) , who looks like he was groomed to make nefarious decisions , ponders their dilemma for a few minutes before deciding that the best thing to do is to bury the body in the desert where she ' ll never be found . although they stomach the gruesome deed of getting rid of the body ( which also disturbingly involves dismantling the body using power saws in order to stuff it into suitcases ) , when they return from their trip , guilt and paranoia begins to set in which slowly consumes some of the five friends . one is adam ( daniel stern ) he grows increasingly agitated . whenever people look at his van or whenever a cop glances his way , his blood pressure increases . or that just may be because of his dysfunctional family . another is michael , who was actually responsible for her death . he tries to bury his feelings , but the burden of guilt begins to affect his judgment as well . boyd is the ? doer ' of the group . seemingly suffering from a long psychosis , when he feels as if his secret is about to be exposed , he is apt to take extreme measures to cover up his tracks . kyle just hopes that his wedding will live up to laura ' s demanding expectations . then , there ' s moore ( leland orser ) who speaks 5 lines and walks around with a puzzled look on his face . the problem with this reprehensible movie is that it wants to be a cruel comedy , but it presents things in a manner that just aren ' t funny . drugs , mutilation , and killing your own friends isn ' t something to be laughed at . as a straight psychological drama , i could see how it might have worked , as each one tried to maneuver and overcome the weight of their own guilt in their own sometimes - sick ways . but this movie insults us by assuming that we could simply discard our values for 2 hours . if you do like this movie , i don ' t think that i want to know you . i did find slater a convincing leader who sways his friends to choose not the right thing but the ? smart play . ' and diaz adds some brightness to this film as a wedding - needing fiancee . but her talents are essentially wasted here . it ' s obvious that the film maker is trying to strike a certain tone . but the way that he chooses to do it is tasteless . do not make a very bad decision by seeing this film \"\n",
    "\n",
    "sent_text = nltk.sent_tokenize(example_sent)\n",
    "sentences = []\n",
    "no_stopwords_sentences = []\n",
    "for sentence in sent_text:\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    no_stopwords_sentences.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(text:str, remove_stopwords:bool = False) -> None:\n",
    "    sent_list = nltk.sent_tokenize(text)\n",
    "    if remove_stopwords:\n",
    "        no_stopwords_sentences = []\n",
    "        for sentence in sent_text:\n",
    "            word_tokens = word_tokenize(sentence)\n",
    "\n",
    "            filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "            filtered_sentence = []\n",
    "            for w in word_tokens:\n",
    "                if w not in stop_words:\n",
    "                    filtered_sentence.append(w)\n",
    "            no_stopwords_sentences.append(filtered_sentence)\n",
    "        return no_stopwords_sentences\n",
    "    else:\n",
    "        return sent_list\n",
    "\n",
    "def get_synsets(sentences:list, ts:'TextServer' = ts) -> list:\n",
    "    r = []\n",
    "    for sent in sentences:\n",
    "        a = ts.senses(sent)\n",
    "        r.append(a)\n",
    "    return r\n",
    "\n",
    "def get_lesk_synsets(text:str, lemmatize:bool = True, remove_stopwords:bool = False):\n",
    "    tokens = word_tokenize(text)\n",
    "    if lemmatize:\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    if remove_stopwords:\n",
    "        tokens = [w for w in tokens if not w.lower() in stop_words]\n",
    "    tagged_tokens = [(a.text, a.pos_) for a in nlp(text)]\n",
    "    words = []\n",
    "    for token, pos in tagged_tokens:\n",
    "        if pos == \"NOUN\":\n",
    "            syn = lesk(tokens, token, pos=\"n\")\n",
    "        elif pos == \"ADJ\":\n",
    "            syn = lesk(tokens, token, pos=\"a\")\n",
    "        elif pos == \"ADV\":\n",
    "            syn = lesk(tokens, token, pos=\"r\")\n",
    "        elif pos == \"VERB\":\n",
    "            syn = lesk(tokens, token, pos=\"v\")\n",
    "        else:\n",
    "            syn = None\n",
    "        if syn is not None:\n",
    "            words.append(syn)\n",
    "    return words\n",
    "\n",
    "def get_lesk_all_synsets(sentences:list, lemmatizer:bool = True) -> list:\n",
    "    all = []\n",
    "    for sentence in sentences:\n",
    "        all.append(get_lesk_synsets(sentence, lemmatizer))\n",
    "    return all\n",
    "    \n",
    "def all_synsets():\n",
    "    for opinion in X_test:\n",
    "        s = get_sentences(opinion)\n",
    "        syns = get_synsets(s)\n",
    "\n",
    "def get_sentiment(synset:'Synset'):\n",
    "    sentiment = swn.senti_synset(synset)\n",
    "    return (sentiment.pos_score(), sentiment.neg_score(), sentiment.obj_score()) if sentiment else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i guess that if a very wild bachelor party had gone really bad , there would be broken furniture , traces of smack and cocaine on the floor , and a dead prostitute in the bathroom .', 'i guess that if a movie had also gone really bad , there might be the same elements present .', 'coincidence ?', 'poor kyle ( a meek looking jon favreau ) .', '.', '.', 'he is about to marry his radiant fiancee , laura ( cameron diaz ) .', 'but before he exchanges his vows , he embarks to las vegas with his friends for one last blowout .', 'but this bachelor party has gone about as bad as it could possibly get .', 'the prostitute has met a horrible , though accidental death , and drugs are everywhere .', 'the five friends agree that there is enough bad evidence here that will send them to jail for a very long time .', \"a surprisingly calm robert boyd ( christian slater ) , who looks like he was groomed to make nefarious decisions , ponders their dilemma for a few minutes before deciding that the best thing to do is to bury the body in the desert where she ' ll never be found .\", 'although they stomach the gruesome deed of getting rid of the body ( which also disturbingly involves dismantling the body using power saws in order to stuff it into suitcases ) , when they return from their trip , guilt and paranoia begins to set in which slowly consumes some of the five friends .', 'one is adam ( daniel stern ) he grows increasingly agitated .', 'whenever people look at his van or whenever a cop glances his way , his blood pressure increases .', 'or that just may be because of his dysfunctional family .', 'another is michael , who was actually responsible for her death .', 'he tries to bury his feelings , but the burden of guilt begins to affect his judgment as well .', 'boyd is the ?', \"doer ' of the group .\", 'seemingly suffering from a long psychosis , when he feels as if his secret is about to be exposed , he is apt to take extreme measures to cover up his tracks .', \"kyle just hopes that his wedding will live up to laura ' s demanding expectations .\", \"then , there ' s moore ( leland orser ) who speaks 5 lines and walks around with a puzzled look on his face .\", \"the problem with this reprehensible movie is that it wants to be a cruel comedy , but it presents things in a manner that just aren ' t funny .\", \"drugs , mutilation , and killing your own friends isn ' t something to be laughed at .\", 'as a straight psychological drama , i could see how it might have worked , as each one tried to maneuver and overcome the weight of their own guilt in their own sometimes - sick ways .', 'but this movie insults us by assuming that we could simply discard our values for 2 hours .', \"if you do like this movie , i don ' t think that i want to know you .\", 'i did find slater a convincing leader who sways his friends to choose not the right thing but the ?', \"smart play . '\", 'and diaz adds some brightness to this film as a wedding - needing fiancee .', 'but her talents are essentially wasted here .', \"it ' s obvious that the film maker is trying to strike a certain tone .\", 'but the way that he chooses to do it is tasteless .', 'do not make a very bad decision by seeing this film .']\n",
      "[[Synset('guess.v.02'), Synset('identical.s.02'), Synset('wilderness.n.03'), Synset('knight_bachelor.n.01'), Synset('party.v.01'), Synset('go.v.10'), Synset('truly.r.01'), Synset('regretful.a.01'), Synset('unwrap.v.02'), Synset('furniture.n.01'), Synset('tracing.n.02'), Synset('smack.n.03'), Synset('floor.n.07'), Synset('dead.s.13'), Synset('prostitute.n.01'), Synset('bathroom.n.01')], [Synset('guess.v.04'), Synset('movie.n.01'), Synset('besides.r.02'), Synset('go.v.10'), Synset('very.r.01'), Synset('regretful.a.01'), Synset('same.a.01'), Synset('component.n.03'), Synset('present.n.03')], [Synset('concurrence.n.04')], [Synset('poor_people.n.01'), Synset('look.v.03')], [], [], [Synset('marry.v.02'), Synset('fiancee.n.01')], [Synset('exchange.n.06'), Synset('vow.v.02'), Synset('venture.v.01'), Synset('friend.n.01'), Synset('last.n.06'), Synset('runaway.n.01')], [Synset('knight_bachelor.n.01'), Synset('party.v.01'), Synset('function.v.01'), Synset('approximately.r.01'), Synset('arsenic.n.02'), Synset('bad.n.01'), Synset('possibly.r.02'), Synset('pay_back.v.02')], [Synset('prostitute.n.01'), Synset('meet.v.11'), Synset('death.n.06'), Synset('drug.v.02'), Synset('everywhere.r.01')], [Synset('friend.n.05'), Synset('agree.v.02'), Synset('be.v.01'), Synset('badly.r.05'), Synset('testify.v.02'), Synset('here.r.03'), Synset('station.v.01'), Synset('jail.n.01'), Synset('very.r.01'), Synset('long.r.01'), Synset('time.v.05')], [Synset('surprisingly.r.01'), Synset('sedate.v.01'), Synset('woodlouse.n.01'), Synset('front.v.01'), Synset('prepare.v.05'), Synset('make.v.42'), Synset('decision.n.04'), Synset('chew_over.v.01'), Synset('dilemma.n.01'), Synset('few.a.01'), Synset('moment.n.01'), Synset('decision_making.n.01'), Synset('well.r.01'), Synset('thing.n.08'), Synset('suffice.v.01'), Synset('bury.v.03'), Synset('soundbox.n.01'), Synset('defect.v.01'), Synset('never.r.01'), Synset('find.v.13')], [Synset('abdomen.n.01'), Synset('deed.n.01'), Synset('rid.v.01'), Synset('soundbox.n.01'), Synset('besides.r.02'), Synset('disturbingly.r.01'), Synset('involve.v.06'), Synset('level.v.02'), Synset('soundbox.n.01'), Synset('use.v.06'), Synset('power.v.01'), Synset('proverb.n.01'), Synset('order.n.14'), Synset('material.n.01'), Synset('bag.n.06'), Synset('return_key.n.01'), Synset('trip.v.04'), Synset('guilt.n.01'), Synset('paranoia.n.01'), Synset('begin.v.08'), Synset('stage_set.n.01'), Synset('lento.r.01'), Synset('devour.v.03'), Synset('friend.n.05')], [Synset('turn.v.07'), Synset('increasingly.r.01'), Synset('stir.v.02')], [Synset('citizenry.n.01'), Synset('spirit.n.02'), Synset('van.n.03'), Synset('bull.n.05'), Synset('glance.v.01'), Synset('way.r.01'), Synset('blood.v.01'), Synset('pressure.n.01'), Synset('increase.n.03')], [Synset('just.a.01'), Synset('family.n.08')], [Synset('actually.r.04'), Synset('responsible.s.02'), Synset('death.n.06')], [Synset('test.v.01'), Synset('immerse.v.03'), Synset('find.v.05'), Synset('effect.n.04'), Synset('guilt.n.01'), Synset('begin.v.08'), Synset('feign.v.01'), Synset('judgment.n.03'), Synset('vitamin_a.n.01'), Synset('well.v.01')], [], [Synset('group.v.02')], [Synset('apparently.r.01'), Synset('suffer.v.11'), Synset('long.a.01'), Synset('psychosis.n.01'), Synset('feel.v.05'), Synset('secret.n.01'), Synset('unwrap.v.02'), Synset('take.v.24'), Synset('measure.n.09'), Synset('shroud.v.01'), Synset('track.n.07')], [Synset('equitable.a.01'), Synset('hope.n.02'), Synset('wedding.n.03'), Synset('survive.v.01'), Synset('demand.v.06'), Synset('expectation.n.03')], [Synset('then.s.01'), Synset('talk.v.01'), Synset('trace.v.02'), Synset('walk.v.05'), Synset('about.r.02'), Synset('spirit.n.02'), Synset('expression.n.01')], [Synset('problem.n.01'), Synset('movie.n.01'), Synset('need.n.02'), Synset('comedy.n.01'), Synset('present.n.03'), Synset('thing.n.08'), Synset('manner.n.01'), Synset('just.r.06'), Synset('triiodothyronine.n.01')], [Synset('drug.v.02'), Synset('mutilation.n.01'), Synset('killing.n.01'), Synset('friend.n.01'), Synset('triiodothyronine.n.01'), Synset('laugh.v.01')], [Synset('heterosexual.n.01'), Synset('psychological.s.01'), Synset('drama.n.04'), Synset('visit.v.01'), Synset('work.v.19'), Synset('one.s.02'), Synset('try_on.v.01'), Synset('manoeuver.v.03'), Synset('get_the_best.v.01'), Synset('weight.n.02'), Synset('guilt.n.01'), Synset('sometimes.r.01'), Synset('vomit.v.01'), Synset('ways.n.01')], [Synset('movie.n.01'), Synset('insult.n.02'), Synset('wear.v.09'), Synset('simply.r.03'), Synset('discard.n.03'), Synset('value.n.03'), Synset('hours.n.01')], [Synset('cause.v.01'), Synset('movie.n.01'), Synset('don.n.06'), Synset('think.v.03'), Synset('want.v.03'), Synset('know.v.02')], [Synset('recover.v.01'), Synset('woodlouse.n.01'), Synset('convincing.a.01'), Synset('leader.n.01'), Synset('swing.v.02'), Synset('supporter.n.01'), Synset('choose.v.03'), Synset('right.n.02'), Synset('thing.n.12')], [Synset('smart.s.07'), Synset('playing_period.n.01')], [Synset('attention_deficit_disorder.n.01'), Synset('brightness.n.02'), Synset('film.n.05'), Synset('wedding.n.03'), Synset('need.v.03'), Synset('fiancee.n.01')], [Synset('talent.n.02'), Synset('basically.r.01'), Synset('waste.v.10'), Synset('here.s.01')], [Synset('obvious.a.01'), Synset('movie.n.01'), Synset('godhead.n.01'), Synset('try_on.v.01'), Synset('strike.n.05'), Synset('certain.a.04'), Synset('tone.n.02')], [Synset('way.r.01'), Synset('choose.v.03'), Synset('do.v.08'), Synset('tasteless.a.02')], [Synset('make.v.15'), Synset('identical.s.02'), Synset('regretful.a.01'), Synset('decisiveness.n.01'), Synset('see.v.10'), Synset('film.v.01')]]\n"
     ]
    }
   ],
   "source": [
    "s = get_sentences(X_test[0])\n",
    "print(s)\n",
    "syns = get_lesk_all_synsets(s)\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_lesk_all_synsets() got an unexpected keyword argument 'lemmatizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[262], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m opinion \u001b[38;5;129;01min\u001b[39;00m X_test:\n\u001b[0;32m      3\u001b[0m     s \u001b[38;5;241m=\u001b[39m get_sentences(opinion)\n\u001b[1;32m----> 4\u001b[0m     syns \u001b[38;5;241m=\u001b[39m \u001b[43mget_lesk_all_synsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     names \u001b[38;5;241m=\u001b[39m [[syn\u001b[38;5;241m.\u001b[39mname() \u001b[38;5;28;01mfor\u001b[39;00m syn \u001b[38;5;129;01min\u001b[39;00m ll] \u001b[38;5;28;01mfor\u001b[39;00m ll \u001b[38;5;129;01min\u001b[39;00m syns]\n\u001b[0;32m      6\u001b[0m     test_synsets\u001b[38;5;241m.\u001b[39mappend(names)\n",
      "\u001b[1;31mTypeError\u001b[0m: get_lesk_all_synsets() got an unexpected keyword argument 'lemmatizer'"
     ]
    }
   ],
   "source": [
    "test_synsets = []\n",
    "for opinion in X_test:\n",
    "    s = get_sentences(opinion)\n",
    "    syns = get_lesk_all_synsets(s, lemmatizer=False)\n",
    "    names = [[syn.name() for syn in ll] for ll in syns]\n",
    "    test_synsets.append(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/lesk_test_synsets.json', 'w') as file:\n",
    "    json.dump(test_synsets, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/lesk_test_synsets.json', 'r') as file:\n",
    "    test_synsets = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed = [\"n\", \"v\", \"r\", \"a\", \"s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "scores_obj = []\n",
    "scores_res = []\n",
    "for opinion in test_synsets:\n",
    "    total_pos = 0\n",
    "    total_neg = 0\n",
    "    total_obj = 0\n",
    "    for sentence in opinion:\n",
    "        filter_sentence = [name for name in sentence if name.split('.')[1] in allowed]\n",
    "        scores = [get_sentiment(syn) for syn in filter_sentence if get_sentiment(syn) != None]\n",
    "        if len(scores) > 0:\n",
    "            total_pos += sum(s[0] for s in scores)/len(scores)\n",
    "            total_neg += sum(s[1] for s in scores)/len(scores)\n",
    "            total_obj += sum(s[2] for s in scores) /len(scores)\n",
    "    score = total_obj\n",
    "    scores_obj.append(total_obj)\n",
    "    scores_res.append(total_pos - total_neg)\n",
    "    if score > 0.15:\n",
    "        # print(\"Positive\")\n",
    "        results.append(1)\n",
    "    elif score < 0.15:\n",
    "        # print(\"Negative\")\n",
    "        results.append(0)\n",
    "    else:\n",
    "        # print(\"Neutral\")\n",
    "        results.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.624\n"
     ]
    }
   ],
   "source": [
    "results = [0 if a < 0.25 else 1 for a in scores_res]\n",
    "print(accuracy_score(y_test, results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
