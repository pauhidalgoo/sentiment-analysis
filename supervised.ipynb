{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SENTIMENT ANALYSIS - SUPERVISED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "with open('./data/X_train.json', 'r') as file:\n",
    "    X_train_data = json.load(file)\n",
    "    \n",
    "with open('./data/X_test.json', 'r') as file:\n",
    "    X_test_data = json.load(file)\n",
    "    \n",
    "with open('./data/y_train.json', 'r') as file:\n",
    "    y_train = json.load(file)\n",
    "    \n",
    "with open('./data/y_test.json', 'r') as file:\n",
    "    y_test = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=0.0, stop_words='english', strip_accents='ascii')\n",
    "\n",
    "vectorizer_alternate = CountVectorizer(min_df=0.05, stop_words='english', strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "X_train_lem = [\" \".join([wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(sent))]) for sent in X_train_data]\n",
    "X_test_lem = [\" \".join([wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(sent))]) for sent in X_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "X_train_pre = []\n",
    "for sent in X_train_lem:\n",
    "    sentence = []\n",
    "    for token in word_tokenize(sent):\n",
    "        if token not in string.punctuation and token not in stop_words and token != \"``\":\n",
    "            sentence.append(token)\n",
    "    X_train_pre.append(\" \".join(e for e in sentence))\n",
    "\n",
    "X_test_pre = []\n",
    "for sent in X_test_lem:\n",
    "    sentence = []\n",
    "    for token in word_tokenize(sent):\n",
    "        if token not in string.punctuation and token not in stop_words and token not in [\"``\", \"--\"]:\n",
    "            sentence.append(token)\n",
    "    X_test_pre.append(\" \".join(e for e in sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem = [\" \".join([stemmer.stem(i) for i in word_tokenize(sent)]) for sent in X_train_data]\n",
    "X_test_stem = [\" \".join([stemmer.stem(i) for i in word_tokenize(sent)]) for sent in X_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(X_train_data)\n",
    "X_test = vectorizer.transform(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_alt = vectorizer_alternate.fit_transform(X_train_data)\n",
    "X_test_alt = vectorizer_alternate.transform(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem = vectorizer.fit_transform(X_train_lem)\n",
    "X_test_lem = vectorizer.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem = vectorizer.fit_transform(X_train_stem)\n",
    "X_test_stem = vectorizer.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre = vectorizer.fit_transform(X_train_pre)\n",
    "X_test_pre = vectorizer.transform(X_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, max_depth=3, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = AdaBoostClassifier(n_estimators=100, algorithm=\"SAMME\", random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.678"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "accuracy_score(clf.predict(X_test.toarray()), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=800, max_depth=12, random_state=0)\n",
    "clf.fit(X_train_stem, y_train)\n",
    "\n",
    "accuracy_score(clf.predict(X_test_stem), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train_pre, y_train)\n",
    "\n",
    "accuracy_score(clf.predict(X_test_pre), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=1, kernel='rbf', degree=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.556"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-3, hidden_layer_sizes=(20, 10), random_state=42)\n",
    "clf.fit(X_train_pre, y_train)\n",
    "accuracy_score(clf.predict(X_test_pre), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search on model: 1/6\r"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# List of models and their hyperparameters\n",
    "random_state = 0\n",
    "models_params = [\n",
    "    (GradientBoostingClassifier(), {'learning_rate': [0.1, 0.25, 0.5], 'max_depth': [3, 6], 'random_state': [random_state]}),\n",
    "    (AdaBoostClassifier(), {'n_estimators': [50, 100, 200], 'algorithm': [\"SAMME\", \"SAMME.R\"], 'learning_rate': [0.5, 1], 'random_state': [random_state]}),\n",
    "    (RandomForestClassifier(), {'n_estimators': [100, 500, 1000, 1500], 'max_depth': [2, 5, 10, 12, 13, 14, None], 'random_state': [random_state]}),\n",
    "    (LogisticRegression(), {'max_iter': [1000] , 'random_state': [random_state]}),\n",
    "    (SVC(), {'C': [0.5, 1, 5], 'kernel': ['linear', 'rbf', 'poly'], 'degree': [1, 2, 3], 'random_state': [random_state]}),\n",
    "    (MLPClassifier(), {'solver': ['lbfgs', 'adam'], 'learning_rate': ['constant', 'adaptive', 'invscaling'], 'hidden_layer_sizes': [(5, 2), (10, 5), (20, 10)], 'alpha': [1e-2, 1e-3, 1e-5], 'random_state': [random_state]})\n",
    "]\n",
    "results = []\n",
    "\n",
    "def run_grid_search(model, params):\n",
    "    \"\"\"\n",
    "    Runs a grid search for the given model and parameters.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(model, params, scoring='accuracy', cv=5)\n",
    "    grid_search.fit(X_train_pre, y_train)\n",
    "    \n",
    "    return grid_search.best_params_, grid_search.best_score_\n",
    "\n",
    "# Run grid search for each model\n",
    "iter = 1\n",
    "for model, params in models_params:\n",
    "    print(f\"Running grid search on model: {iter}/{len(models_params)}\\r\", end=\"\")\n",
    "    best_params, best_score = run_grid_search(model, params)\n",
    "    results.append((model.__class__.__name__, best_params, best_score))\n",
    "    iter += 1\n",
    "\n",
    "# Show results\n",
    "for model_name, best_params, best_score in results:\n",
    "    print(f\"{model_name}: Best params = {best_params} (Accuracy = {best_score:.4f})\")\n",
    "\n",
    "best_model = max(results, key=lambda x: x[2])\n",
    "print(f\"BEST MODEL: {best_model[0]} with params = {best_model[1]} (Accuracy = {best_model[2]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the best model on the test set\n",
    "best_clf = RandomForestClassifier(max_depth=12, n_estimators=1500, random_state=random_state)\n",
    "best_clf.fit(X_train, y_train)\n",
    "accuracy_score(best_clf.predict(X_test), y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
